import time
import os
import pandas as pd
import mrmr
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import recall_score, precision_score, accuracy_score
import plotext as plt
from joblib import dump, load
from imblearn.over_sampling import SMOTE


pathtofile = os.environ['PATH_TO_FILE']
maxfeatures = int(os.environ['MAX_FEATURES'])
usesmote = bool(os.environ['USE_SMOTE'])

df = pd.read_csv(pathtofile)

breakdown = df.fillna(2).apply(pd.Series.value_counts)

for column in breakdown:
    target = breakdown[column]
    total = target.sum(axis=0)

    if column == "Result":
        positives = target[1]
        negatives = target[0]

    for i in target.index:
        if target[i]/total < 0.001:
            print(column + " is extremely skewed")
        elif target[i]/total < 0.01:
            print(column + " is skewed")
        elif i == 2 and target[i]/total > 0.05:
            print(column + " is nulled a lot")


print(" ")
print("Total Rows:")
print(total)
print("Positive Examples:")
print(positives)
print("Negative Examples:")
print(negatives)

#This gets a priority list with K=86
selected_features = mrmr.mrmr_classif(X=df.drop(['Result'], axis=1), y=df['Result'], K=86)

if not usesmote:
    x_train, x_test, y_train, y_test = train_test_split(df.drop(['Result'], axis =1), df['Result'],
                                                        test_size=0.10,
                                                        random_state=0,
                                                        stratify=df['Result'])
else:
    X_resampled, y_resampled = SMOTE().fit_resample(df.drop(['Result'], axis=1), df['Result'])
    smote_breakdown = pd.Series.value_counts(y_resampled)
    print("SMOTE-d Positives:")
    print(smote_breakdown[1])
    print("SMOTE-d Negatives:")
    print(smote_breakdown[0])
    x_train, x_test, y_train, y_test = train_test_split(X_resampled,y_resampled,
                                                        test_size=0.10,
                                                        random_state=0)
print("Going to training")


def runSweep(model_to_test, parameter_space, prefixx, maxF):
    accuracy_df = pd.DataFrame(columns=['Number of Features', 'Accuracy'])
    recall_df = pd.DataFrame(columns=['Number of Features', 'Accuracy'])
    precision_df = pd.DataFrame(columns=['Number of Features', 'Accuracy'])

    best_recall = 0.0
    best_model = ""

    os.mkdir(prefixx)
    for n in range(1, maxF):
        subset_features = selected_features[0:n]
        model_to_test.fit(x_train[subset_features], y_train)
        y_pred = model_to_test.predict(x_test[subset_features])
        recall_scoree = recall_score(y_test, y_pred)
        recall_df = pd.concat([recall_df, pd.DataFrame([{'Number of Features': n, 'Recall': recall_score(y_test, y_pred)}])], axis=0, ignore_index=True)
        precision_df = pd.concat([precision_df, pd.DataFrame([{'Number of Features': n, 'Precision': precision_score(y_test, y_pred)}])], axis=0, ignore_index=True)
        accuracy_df = pd.concat([accuracy_df, pd.DataFrame([{'Number of Features': n, 'Accuracy': accuracy_score(y_test, y_pred)}])], axis=0, ignore_index=True)
        filenamee = prefixx+"/feature"+str(n)
        dump(model_to_test, filenamee)
        if recall_scoree > best_recall:
            best_recall = recall_scoree
            best_model = filenamee

    plt.plot(accuracy_df['Number of Features'], accuracy_df['Accuracy'])
    plt.title('Accuracy vs. Number of Features')
    plt.xlabel('Number of Features')
    plt.ylabel('Accuracy')
    plt.grid(True)
    plt.xlim(0, maxF)
    plt.show()
    plt.clear_data()
    plt.plot(precision_df['Number of Features'], precision_df['Precision'])
    plt.title('Precision vs. Number of Features')
    plt.xlabel('Number of Features')
    plt.ylabel('Precision')
    plt.grid(True)
    plt.xlim(0, maxF)
    plt.show()
    plt.clear_data()
    plt.plot(recall_df['Number of Features'], recall_df['Recall'])
    plt.title('Recall vs. Number of Features')
    plt.xlabel('Number of Features')
    plt.ylabel('Recall')
    plt.grid(True)
    plt.xlim(0, maxF)
    plt.show()
    plt.clear_data()

    print("The best model is saved at '"+best_model+"' and has a recall score of "+str(best_recall))


dirname = os.path.dirname(__file__)
fileprefix = os.path.join(dirname, "/models/")
os.mkdir(fileprefix)

#nnParams = {'hidden_layer_sizes': [(10, 30, 10), (20,)], 'alpha': [0.0001], 'learning_rate_init': [0.05]}
#Large nnParams set
nnParams = {'hidden_layer_sizes': [(10, 30, 10), (20,)], 'alpha': [0.0001, 0.01], 'learning_rate_init': [0.05]}
runSweep(GridSearchCV(MLPClassifier(), nnParams, cv=5, scoring='recall', n_jobs=-1), nnParams, fileprefix+"nnModel", maxfeatures)

adaParams = {}
runSweep(AdaBoostClassifier(n_estimators=50, learning_rate=1), adaParams, fileprefix+"adaModel", 86)

os.system('cp -r '+fileprefix+'/* /tmp/')

#just in case.....
time.sleep(1)
quit()
